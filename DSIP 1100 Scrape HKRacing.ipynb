{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download SCMP\n",
    "\n",
    "This notebook will scrape every record of a horse that has raced in Hong Kong which SCMP possesses.  Using a page of JSON HKRacing generates when given an empty search, it runs through the list of every horse on the site, recording every race each has taken part in, as well as a variety of other variables. \n",
    "\n",
    "## Import  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import json \n",
    "import csv\n",
    "import os\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "import requests \n",
    "\n",
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape the page of JSON that HKRacing generates when you give it a search for a horse name.  In this case we're scrapping the page that results from searching an emmpty space, since this gives you the full list of all horses recorded on HKRacing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "requests.models.Response"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.scmp.com/sport/racing/ajax/horses-search/HorseName/%20'\n",
    "hk_url = 'https://www.scmp.com/sport/racing/stats/horses/{}/{}'\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "requested_json = requests.get(url, headers=headers)\n",
    "type(requested_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the request object that returns from scraping the webpage and slice out the first {data:...} tab so that the result isn't nested and can be easily normalized.  Once that data tag has been removed, convert the string response into a JSON dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_json = requested_json.content.decode()\n",
    "sliced_json = decoded_json[8:-1]\n",
    "loaded_json = json.loads(sliced_json)\n",
    "type(loaded_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the JSON Dictionary into a Data Frame that we will be able to iterate through while scraping the full pages for each horse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>horse_id</th>\n",
       "      <th>horse_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>B340</td>\n",
       "      <td>B340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>V614</td>\n",
       "      <td>A SHIN HIKARI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>B345</td>\n",
       "      <td>ABOVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A328</td>\n",
       "      <td>ABSOLUCOOL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>P626</td>\n",
       "      <td>ABSOLUTELY WIN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index horse_id      horse_name\n",
       "0      0     B340            B340\n",
       "1      1     V614   A SHIN HIKARI\n",
       "2      2     B345           ABOVE\n",
       "3      3     A328      ABSOLUCOOL\n",
       "4      4     P626  ABSOLUTELY WIN"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_json = json_normalize(loaded_json['result'])\n",
    "indexed_json = normal_json.reset_index()\n",
    "indexed_json.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Spider\n",
    "\n",
    "Create a spider using scrapy to crawl the scmp website.  For each entry in the JSON retrieved earlier, the spider will go to that page and retrieve all relevant information as marked below.  It will all be saved in the file desginated under custom_settings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HKSpider(scrapy.Spider):\n",
    "\n",
    "    name = \"hkracing_spider\"\n",
    "    allowed_domains = ['www.scmp.com']\n",
    "\n",
    "    custom_settings = {\n",
    "        'FEED_FORMAT':'csv', \n",
    "        'FEED_URI':'hkhorses.csv'\n",
    "    }\n",
    "    \n",
    "    def start_requests(self): \n",
    "        #for each Horse\n",
    "        for index in indexed_json['index'].values: \n",
    "            yield scrapy.Request(\n",
    "                hk_url.format(indexed_json.at[index, 'horse_id'], indexed_json.at[index, 'horse_name']\\\n",
    "                    .strip().lower().replace(\" \", \"-\")),\n",
    "                self.get_horse,\n",
    "            )\n",
    "    \n",
    "    def get_horse(self, response):\n",
    "        print(\"processing: \" + response.url)\n",
    "        \n",
    "        name=response.xpath(\"//div[@class='wrapper']//div[@class='header']//h1/text()\").extract()\n",
    "        sire=response.xpath(\"//div[@class='wrapper']//div[@class='details']//p/text()[11]\").extract()\n",
    "        dame=response.xpath(\"//div[@class='wrapper']//div[@class='details']//p/text()[13]\").extract()\n",
    "        date=response.xpath(\"//div[@class='race-table']//tbody//tr//td[1]//text()\").extract()\n",
    "        race_number=response.xpath(\"//div[@class='race-table']//tbody//tr//td[2]//a/text()\").extract()\n",
    "        track=response.xpath(\"//div[@class='race-table']//tbody//tr//td[3]/text()\").extract()\n",
    "        distance=response.xpath(\"//div[@class='race-table']//tbody//tr//td[4]/text()\").extract()\n",
    "        cl=response.xpath(\"//div[@class='race-table']//tbody//tr//td[5]/text()\").extract()\n",
    "        rank=response.xpath(\"//div[@class='race-table']//tbody//tr//td[6]/text()\").extract()\n",
    "        trainer=response.xpath(\"//div[@class='race-table']//tbody//tr//td[7]/text()\").extract()\n",
    "        weight=response.xpath(\"//div[@class='race-table']//tbody//tr//td[8]/text()\").extract()\n",
    "        jockey=response.xpath(\"//div[@class='race-table']//tbody//tr//td[9]/text()\").extract()\n",
    "        dr=response.xpath(\"//div[@class='race-table']//tbody//tr//td[10]/text()\").extract()\n",
    "        gr=response.xpath(\"//div[@class='race-table']//tbody//tr//td[11]/text()\").extract()\n",
    "        win_time=response.xpath(\"//div[@class='race-table']//tbody//tr//td[15]/text()\").extract()\n",
    "        last_qtr=response.xpath(\"//div[@class='race-table']//tbody//tr//td[16]/text()\").extract()\n",
    "        section_time=response.xpath(\"//div[@class='race-table']//tbody//tr//td[17]/text()\").extract()\n",
    "        ln_running=response.xpath(\"//div[@class='race-table']//tbody//tr//td[18]/text()\").extract()\n",
    "        w_m=response.xpath(\"//div[@class='race-table']//tbody//tr//td[19]/text()\").extract()\n",
    "        horse_wt=response.xpath(\"//div[@class='race-table']//tbody//tr//td[20]/text()\").extract()\n",
    "        rt=response.xpath(\"//div[@class='race-table']//tbody//tr//td[21]/text()\").extract()\n",
    "        odds_on=response.xpath(\"//div[@class='race-table']//tbody//tr//td[22]/text()\").extract()\n",
    "        odds_last=response.xpath(\"//div[@class='race-table']//tbody//tr//td[23]/text()\").extract()\n",
    "        \n",
    "        \n",
    "        row_data=zip(date, race_number, track, distance, cl, rank, trainer, weight, jockey, dr, gr, win_time, last_qtr, section_time, ln_running, w_m, horse_wt, rt, odds_on, odds_last)\n",
    "        \n",
    "        \n",
    "        for item in row_data: \n",
    "            scraped_info = {\n",
    "                'name':name, \n",
    "                'sire':sire, \n",
    "                'dame':dame, \n",
    "                'date':item[0], \n",
    "                'race_number':item[1], \n",
    "                'track':item[2], \n",
    "                'distance':item[3], \n",
    "                'cl':item[4], \n",
    "                'rank':item[5], \n",
    "                'trainer':item[6], \n",
    "                'weight':item[7], \n",
    "                'jockey':item[8], \n",
    "                'dr':item[9], \n",
    "                'gr':item[10], \n",
    "                'win_time':item[11], \n",
    "                'last_qtr':item[12], \n",
    "                'section_time':item[13], \n",
    "                'ln_running':item[14], \n",
    "                'w_m':item[15], \n",
    "                'horse_wt':item[16], \n",
    "                'rt':item[17], \n",
    "                'odds_on':item[18], \n",
    "                'odds_last':item[19],\n",
    "            }\n",
    "            yield scraped_info "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve and Store Data\n",
    "\n",
    "Run the scrapy spider so long as you don't already have the data, and making sure to look like a browser while you do. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-10 15:22:01 [scrapy.utils.log] INFO: Scrapy 1.5.2 started (bot: scrapybot)\n",
      "2019-05-10 15:22:01 [scrapy.utils.log] INFO: Versions: lxml 4.3.2.0, libxml2 2.9.9, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.9.0, Python 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1b  26 Feb 2019), cryptography 2.6.1, Platform Windows-10-10.0.17763-SP0\n"
     ]
    }
   ],
   "source": [
    "process = CrawlerProcess({\n",
    "    'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'\n",
    "})\n",
    "\n",
    "process.settings['LOG_LEVEL']='WARNING'\n",
    "\n",
    "if not(os.path.isfile('hkhorses.csv')): \n",
    "    process.crawl(HKSpider)\n",
    "    process.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double check here that the data reads properly and looks like what you'd expect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17449, 23)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hk_csv = pd.read_csv('hkhorses.csv')\n",
    "hk_csv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sire</th>\n",
       "      <th>dame</th>\n",
       "      <th>date</th>\n",
       "      <th>race_number</th>\n",
       "      <th>track</th>\n",
       "      <th>distance</th>\n",
       "      <th>cl</th>\n",
       "      <th>rank</th>\n",
       "      <th>trainer</th>\n",
       "      <th>...</th>\n",
       "      <th>gr</th>\n",
       "      <th>win_time</th>\n",
       "      <th>last_qtr</th>\n",
       "      <th>section_time</th>\n",
       "      <th>ln_running</th>\n",
       "      <th>w_m</th>\n",
       "      <th>horse_wt</th>\n",
       "      <th>rt</th>\n",
       "      <th>odds_on</th>\n",
       "      <th>odds_last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A SHIN HIKARI (V614) 榮進之光</td>\n",
       "      <td>Deep Impact</td>\n",
       "      <td>Catalina</td>\n",
       "      <td>11-12-16</td>\n",
       "      <td>257</td>\n",
       "      <td>ST tf g A</td>\n",
       "      <td>2000</td>\n",
       "      <td>G1</td>\n",
       "      <td>10</td>\n",
       "      <td>M. Sakaguchi</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>2:00.9</td>\n",
       "      <td>24.10</td>\n",
       "      <td>73.34 23.46 25.38</td>\n",
       "      <td>1-1-1-10</td>\n",
       "      <td>7.75</td>\n",
       "      <td>1134</td>\n",
       "      <td>129</td>\n",
       "      <td>6.8</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A SHIN HIKARI (V614) 榮進之光</td>\n",
       "      <td>Deep Impact</td>\n",
       "      <td>Catalina</td>\n",
       "      <td>13-12-15</td>\n",
       "      <td>251</td>\n",
       "      <td>ST tf g A</td>\n",
       "      <td>2000</td>\n",
       "      <td>G1</td>\n",
       "      <td>1</td>\n",
       "      <td>M. Sakaguchi</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>2:00.6</td>\n",
       "      <td>23.60</td>\n",
       "      <td>73.39 23.59 23.62</td>\n",
       "      <td>1-1-1-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1111</td>\n",
       "      <td>114</td>\n",
       "      <td>28</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABSOLUTELY WIN (P626) 肯定贏</td>\n",
       "      <td>Oasis Dream</td>\n",
       "      <td>Five Fields</td>\n",
       "      <td>02-03-13</td>\n",
       "      <td>432</td>\n",
       "      <td>ST tf g C</td>\n",
       "      <td>1400</td>\n",
       "      <td>G3</td>\n",
       "      <td>11</td>\n",
       "      <td>G. W. Moore</td>\n",
       "      <td>...</td>\n",
       "      <td>B</td>\n",
       "      <td>1:22.0</td>\n",
       "      <td>23.60</td>\n",
       "      <td>35.43 23.00 24.60</td>\n",
       "      <td>1-1-1-11</td>\n",
       "      <td>6.25</td>\n",
       "      <td>1111</td>\n",
       "      <td>94</td>\n",
       "      <td>6.8</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADONIS (A324) 明月昇輝</td>\n",
       "      <td>Exceed And Excel</td>\n",
       "      <td>Mythical Play</td>\n",
       "      <td>14-04-19</td>\n",
       "      <td>575</td>\n",
       "      <td>ST tf g C</td>\n",
       "      <td>1200</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>L. Ho</td>\n",
       "      <td>...</td>\n",
       "      <td>H/PC</td>\n",
       "      <td>1:10:00</td>\n",
       "      <td>23.79</td>\n",
       "      <td>24.90 21.95 23.68</td>\n",
       "      <td>8-6-5</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1043</td>\n",
       "      <td>34</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADONIS (A324) 明月昇輝</td>\n",
       "      <td>Exceed And Excel</td>\n",
       "      <td>Mythical Play</td>\n",
       "      <td>24-03-19</td>\n",
       "      <td>520</td>\n",
       "      <td>ST tf g C+3</td>\n",
       "      <td>1400</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>L. Ho</td>\n",
       "      <td>...</td>\n",
       "      <td>H/PC</td>\n",
       "      <td>1:23:23</td>\n",
       "      <td>24.13</td>\n",
       "      <td>36.61 23.09 23.78</td>\n",
       "      <td>8-8-6-4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1033</td>\n",
       "      <td>34</td>\n",
       "      <td>9.1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          name               sire            dame      date  \\\n",
       "0  A SHIN HIKARI (V614) 榮進之光          Deep Impact        Catalina  11-12-16   \n",
       "1  A SHIN HIKARI (V614) 榮進之光          Deep Impact        Catalina  13-12-15   \n",
       "2  ABSOLUTELY WIN (P626) 肯定贏          Oasis Dream     Five Fields  02-03-13   \n",
       "3         ADONIS (A324) 明月昇輝     Exceed And Excel   Mythical Play  14-04-19   \n",
       "4         ADONIS (A324) 明月昇輝     Exceed And Excel   Mythical Play  24-03-19   \n",
       "\n",
       "   race_number        track  distance  cl rank       trainer  ...     gr  \\\n",
       "0          257    ST tf g A      2000  G1   10  M. Sakaguchi  ...  H       \n",
       "1          251    ST tf g A      2000  G1    1  M. Sakaguchi  ...  H       \n",
       "2          432    ST tf g C      1400  G3   11   G. W. Moore  ...  B       \n",
       "3          575    ST tf g C      1200   5    5         L. Ho  ...   H/PC   \n",
       "4          520  ST tf g C+3      1400   5    4         L. Ho  ...   H/PC   \n",
       "\n",
       "  win_time  last_qtr        section_time ln_running   w_m horse_wt   rt  \\\n",
       "0   2:00.9     24.10   73.34 23.46 25.38   1-1-1-10  7.75     1134  129   \n",
       "1   2:00.6     23.60   73.39 23.59 23.62    1-1-1-1     1     1111  114   \n",
       "2   1:22.0     23.60   35.43 23.00 24.60   1-1-1-11  6.25     1111   94   \n",
       "3  1:10:00     23.79  24.90 21.95 23.68       8-6-5  3.25     1043   34   \n",
       "4  1:23:23     24.13   36.61 23.09 23.78    8-8-6-4   1.5     1033   34   \n",
       "\n",
       "  odds_on odds_last  \n",
       "0     6.8       8.6  \n",
       "1      28        38  \n",
       "2     6.8       7.1  \n",
       "3     3.8       2.7  \n",
       "4     9.1        12  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hk_csv.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
